{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c4141a-0449-4650-8301-8eca3c94e48e",
   "metadata": {},
   "source": [
    "# Profile classification according to the number of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76127ac3-7367-438b-bf7c-ba4c8f357b68",
   "metadata": {},
   "source": [
    "Once we finished our approaches, we are going to classify all our profiles according to their number of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4454afe9-1e8a-4bfc-9779-a86c92cdad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, some imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotting_functions as plot\n",
    "\n",
    "#Now we read the data\n",
    "from read_CTD import read_CTD\n",
    "data_dirs = ['C:/Users/Pau/Data/TFM/CTD_proc_files_1mbin/']\n",
    "data=read_CTD(data_dirs)\n",
    "\n",
    "#And delete the outliers\n",
    "from out_outliers import out_outliers\n",
    "for ncast in data.keys():\n",
    "    for variable in data[ncast].columns:\n",
    "        out_outliers(data, ncast, variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd10a5d2-84ff-4f40-ae14-4ef511ae8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code that creates the layers' classification tables\n",
    "#Import the different functions that correspond to the different approaches that determines the layers of a vertical profiles\n",
    "from inflexion_points import inflexion_points     #1st approach\n",
    "from maxmin import maxmin, maxmin_2               #2nd and 3rd approach\n",
    "#We will smooth the profiles with a lamb=5.000.000 except for the 1st that will be of 50.000.000\n",
    "lamb=5000000\n",
    "\n",
    "#1st we create a series that contains the number of layers of each profile\n",
    "table1 = pd.Series(dtype=np.int64)\n",
    "table2 = pd.Series(dtype=np.int64)\n",
    "table3 = pd.Series(dtype=np.int64)\n",
    "for ncast in data.keys():\n",
    "    table1[ncast]=inflexion_points(data, ncast, lamb=50000000)    #Series of the 1st approach\n",
    "    table2[ncast]=maxmin(data, ncast, lamb=lamb)              #Series of the 2nd approach\n",
    "    table3[ncast]=maxmin_2(data, ncast, lamb=lamb)            #Series of the 3rd approach\n",
    "    \n",
    "#Now, we transform the series and create a table that classifies the profiles according to their number of layers\n",
    "layers1 = pd.Series(index=set(table1.values), dtype=np.int64)\n",
    "layers2 = pd.Series(index=set(table2.values), dtype=np.int64)\n",
    "layers3 = pd.Series(index=set(table3.values), dtype=np.int64)\n",
    "\n",
    "for a, b, c in zip(table1.values, table2.values, table3.values):\n",
    "    #print(a,b,c)\n",
    "    layers1[a]=list(table1[table1==a].index)\n",
    "    layers2[b]=list(table2[table2==b].index)\n",
    "    layers3[c]=list(table3[table3==c].index)\n",
    "layers1.index.name = 'Nº of layers (1st approach) - [ncast profile]'\n",
    "layers2.index.name = 'Nº of layers (2nd approach) - [ncast profile]'\n",
    "layers3.index.name = 'Nº of layers (3rd approach) - [ncast profile]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab9f43-afc1-45dc-9600-d76adb4062cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CLASSIFICATIONS\n",
    "\n",
    "We created 3 tables, one for each approach. It is important to remark that the results vary significantly in function of how much we smooth the profile. We opted for a significant smooth to observe just the big scale features. To choose how much we smoothed the profile, we used the functions that plot the profiles separated by its layers and decided subjectively which one fit better.\n",
    "\n",
    "\n",
    "The 3 classifications are similar, especially the second and the third that are almost exact. We could expect it, because when work with very smooth profiles ,the second approach does not detect many layers closer than 50m. Most of the profiles are classified between 3 and 4 layers. Profiles in the first approach range from 2 to 7 layers and in the second and third approaches range from 2 to 6 layers.\n",
    "\n",
    "\n",
    "In the next section, we will create some maps to observe better those classifications and see if the layer classifications follow any kind of pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c921f-0443-40e4-be6e-d0019563cd84",
   "metadata": {},
   "source": [
    "### 1st Approach - Inflexion Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7def5efe-018e-4f1f-9c4d-cadaf2092780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nº of layers (1st approach) - [ncast profile]\n",
       "2                                 [09, 14, 34, 35, 46]\n",
       "3     [10, 11, 12, 13, 16, 21, 22, 27, 28, 29, 33, 36]\n",
       "4    [19, 25, 26, 30, 31, 32, 37, 38, 41, 42, 43, 4...\n",
       "5                                             [17, 40]\n",
       "6                                 [15, 18, 20, 24, 39]\n",
       "7                                                 [23]\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dff8e7-d938-4b35-a07f-8c1ef71c75ef",
   "metadata": {},
   "source": [
    "### 2nd Approach - Relative Maximums and Minimums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26fea223-bbd7-4d00-b230-0d4036a9ffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nº of layers (2nd approach) - [ncast profile]\n",
       "2                     [09, 10, 11, 13, 14, 17, 21, 22]\n",
       "3     [12, 15, 16, 19, 28, 29, 33, 34, 35, 36, 45, 46]\n",
       "4    [26, 27, 30, 31, 32, 37, 38, 39, 40, 41, 42, 4...\n",
       "5                                     [18, 23, 24, 25]\n",
       "6                                                 [20]\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b2ad6-56bf-4fdf-ac37-0e6809fd73cb",
   "metadata": {},
   "source": [
    "### 3rd Approach - Relative Maximums and Minimums v2 (no max/mins closer than 50dbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ef82eb-6c08-4c8c-9855-902b59e3b003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nº of layers (3rd approach) - [ncast profile]\n",
       "2                     [09, 10, 11, 13, 14, 17, 21, 22]\n",
       "3     [12, 15, 16, 19, 28, 29, 33, 34, 35, 36, 45, 46]\n",
       "4    [24, 26, 27, 30, 31, 32, 37, 38, 39, 40, 41, 4...\n",
       "5                                         [18, 23, 25]\n",
       "6                                                 [20]\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
